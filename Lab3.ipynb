{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Lab 3 — Data Cleaning (Outliers • Inconsistencies • Missingness)\n",
    "\n",
    "**Overview**  \n",
    "In this lab, you will take the synthetic opioid dataset from “raw” to “analysis-ready.” You’ll make a working copy, profile the data, and apply clear, defensible cleaning rules. We’ll start with quantitative hair toxicology signals (outliers), reconcile self-report vs. hair results (inconsistencies + branch/skip checks), and finish by auditing and handling missing data. Every decision should be documented so another analyst could reproduce your steps.\n",
    "\n",
    "**Learning Objectives**  \n",
    "By the end of this lab, you will be able to:\n",
    "- Create a protected working copy (`clean_df`) and record a concise change log of cleaning actions.\n",
    "- **Outliers:** Detect with the IQR rule; choose and justify a remedy (cap/winsorize vs. transform), and show before/after plots.\n",
    "- **Inconsistencies:** Verify gate/skip logic; build a self-report ↔ hair **discordance flag** and state an analysis rule (e.g., conservative combine vs. window-aware note).\n",
    "- **Missingness:** Map standardized nonresponse codes (e.g., 222/444/555/666/777/888/999) to `NaN` as appropriate; quantify missingness and reason about MCAR/MAR/MNAR.\n",
    "- Re-check summaries after cleaning to confirm issues are resolved and figures/tables align with your stated rules.\n",
    "\n",
    "**Dataset & Context**\n",
    "\n",
    "This lab uses the **same dataset from Lab 2** (synthetic ABCD opioid data). Hair toxicology provides a biological measure of substance use over roughly the past 90 days, while self‑report measures capture the participant’s recall during a specific window. Careful cleaning and documentation are essential for any analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "\n",
    "**Grading Note:**  \n",
    "Complete all sections of this notebook, then **save it as `Lab3.ipynb`** before submission.  \n",
    "If you are working in VS Code/Codespaces, use **File → Download** to save the `.ipynb` to your local machine.\n",
    "\n",
    "See the **Grade Rubric** at the end of the notebook before submitting. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 0.1 — DataFrame Hygiene (Read This First)\n",
    "\n",
    "In this lab, you’ll be creating **multiple versions of the same dataset**.  \n",
    "This isn’t just busywork — it’s a core part of professional data cleaning and analysis.  \n",
    "Why? Because we need to **track exactly what changes were made, when, and why** so that we can compare “before” and “after” results without accidentally overwriting the original data.\n",
    "\n",
    "We will keep **exactly three** main DataFrames:\n",
    "\n",
    "- **`df_raw`** — The original dataset, untouched.  \n",
    "  - Loaded once at the start and never modified.  \n",
    "  - Serves as our “ground truth” for reference and allows us to restart the cleaning process without having to reload or re-download data.\n",
    "\n",
    "- **`df_out`** — A working copy of `df_raw` used for **outlier handling** (winsorizing, transforming, or removing extreme values).  \n",
    "  - Any figures or summary statistics in **Part 1** will use `df_out`.  \n",
    "  - Keeping this separate means we can always go back and check how outlier handling changed the data.\n",
    "\n",
    "- **`df_imp`** — A copy of `df_out` used in **Part 3** for missing-data handling (imputation).  \n",
    "  - Instead of overwriting existing variables, we create new columns with a `*_imp` suffix for imputed versions.  \n",
    "  - This lets us directly compare the original cleaned values with the imputed ones.\n",
    "\n",
    "### Why this matters:\n",
    "- **Before/After Comparisons** — You can only measure the impact of cleaning steps if you keep the “before” version intact.  \n",
    "- **Reproducibility** — Clear versioning helps you (and graders) follow your workflow and confirm your results.  \n",
    "- **Avoiding Accidental Changes** — Without separate DataFrames, one line of code could silently overwrite your original data.  \n",
    "- **Easier Debugging** — If something looks off, you can retrace which DataFrame the change happened in.\n",
    "\n",
    "> **Pro tip:** If you create a temporary DataFrame for testing, name it `df_tmp` and delete it after use to avoid confusion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.2 — Setup: paths, imports, load df_raw, and version scaffolding\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "FIG_DIR = Path(\"./figures\"); FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# --- Load the dataset ONCE ---\n",
    "\n",
    "df_raw = ___ # TODO insert pandas code to load the dataset L2L3dataset.csv\n",
    "\n",
    "# Working copies for lab sections\n",
    "df_out = df_raw.copy()   # outliers section → edits happen here\n",
    "df_imp = df_out.copy()   # missing-data section → new *_imp columns are added here\n",
    "\n",
    "# Course-standard special codes\n",
    "SPECIAL_MISS = {777: np.nan, 888: np.nan, 999: np.nan}\n",
    "\n",
    "# Helper: ensure columns exist\n",
    "def existing(cols, df):\n",
    "    return [c for c in cols if c in df.columns]\n",
    "\n",
    "# Helper: numeric conversion column-wise\n",
    "def numify(df, cols):\n",
    "    out = df[cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return out\n",
    "\n",
    "print(\"DataFrames ready: df_raw (original), df_out (outlier work), df_imp (missing-data & *_imp columns).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Part 1 — Hair toxicology outlier check (pick ONE analyte)\n",
    "\n",
    "**Goal:**  \n",
    "Choose one quantitative hair toxicology variable.  \n",
    "1. Inspect its distribution and flag values using ABCD LOQ/LOD (40/20 pg/mg) and a literature-based upper benchmark.  \n",
    "2. Preview handling options for outliers.  \n",
    "3. Apply one method (cap or transform) and report before/after results.\n",
    "\n",
    "**Pick one analyte variable:**\n",
    "- `su_y_hairtox__rslt__opi__hc_qnt` (Hydrocodone; upper 15,000 pg/mg)\n",
    "- `su_y_hairtox__rslt__opi__oc_qnt` (Oxycodone; upper 26,000 pg/mg)\n",
    "- `su_y_hairtox__rslt__opi__cod_qnt` (Codeine; upper 20,000 pg/mg)\n",
    "- `su_y_hairtox__rslt__opi__mor_qnt` (Morphine; upper 13,000 pg/mg)\n",
    "\n",
    "**Context columns to display with flagged values:**  \n",
    "- `su_y_hairtox__coll_002` (collection info)  \n",
    "- `su_y_hairtox__lab_len` (hair length)  \n",
    "- `su_y_hairtox__lab_weight` (hair weight)\n",
    "\n",
    "**Instructions:**  \n",
    "- Replace special codes (777, 999) with `NaN`.\n",
    "- Visualize the distribution (histogram).\n",
    "- Flag values below LOD (20), below LOQ (40), and above the upper benchmark.\n",
    "- Compare before/after using your chosen handling method (capping or transformation).\n",
    "- Briefly describe your choice\n",
    "\n",
    "### Key Terms for Hair Toxicology (ABCD & Literature)\n",
    "\n",
    "Before working with outliers, it’s important to understand how hair toxicology data are reported and flagged:\n",
    "\n",
    "- **LOD (Limit of Detection):** The smallest amount of analyte that can be reliably distinguished from zero.  \n",
    "  - For ABCD hair toxicology, values **< LOD (20 pg/mg)** are considered *not reliably detected*.  \n",
    "\n",
    "- **LOQ (Limit of Quantification):** The smallest concentration that can be measured with acceptable precision and accuracy.  \n",
    "  - For ABCD hair toxicology, values **< LOQ (40 pg/mg)** are *detected but not quantifiable with confidence*.  \n",
    "\n",
    "👉 See [ABCD Hair Toxicology documentation](https://docs.abcdstudy.org/latest/documentation/non_imaging/su.html#su_y_hairtox) for official definitions and procedures.  \n",
    "\n",
    "- **Upper benchmark (from literature):** For each analyte, studies sometimes report a **maximum plausible concentration** based on typical human exposure and contamination limits.  \n",
    "  - These **literature-based “upper” values** (e.g., 15,000 pg/mg for hydrocodone, 10,000 pg/mg for oxycodone) are used as **audit thresholds**, not operational cutoffs.  \n",
    "  - Any value above this benchmark should be double-checked for plausibility (contamination, lab error, etc.).\n",
    "\n",
    "📖 *The citations for these upper benchmarks are listed at the end of the notebook, after the Grade Rubric.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Part 1 — Outlier Handling (Hair Toxicology)\n",
    "\n",
    "**Goal:** Tame extreme values in hair toxicology **quantitative** variables using a **two-tier approach** that keeps analysis data-driven while still auditing plausibility.\n",
    "\n",
    "---\n",
    "\n",
    "### Tier A — Choose **one** robust, sample-specific cap (used for analysis)\n",
    "\n",
    "All caps are computed on the **log scale** to stabilize right-skew and reduce the influence of large values. We then back-transform the chosen cap to the raw pg/mg scale and (typically) **winsorize** values above it in `df_out` (raw column is never overwritten; a `*_wz` column is created).\n",
    "\n",
    "### 1) **Log-IQR upper** (Tukey fence on log values)\n",
    "- **What it is:**  \n",
    "  $$\n",
    "  \\text{log\\_cap} = Q3 + 1.5 \\times IQR\n",
    "  $$\n",
    "  computed on $\\log(1+x)$ (or $\\log_{10}(x)$), then back-transformed.\n",
    "\n",
    "- **When to prefer:** You want a **structure-aware** threshold that adapts to distributional spread; good when tails are long but not dominated by a handful of extremes.\n",
    "- **Pros:** Robust to outliers; reflects within-sample dispersion; widely taught/transparent.\n",
    "- **Cons:** If the top tail is very thick, IQR may still yield a relatively **high** cap; may keep more large values than you want.\n",
    "\n",
    "**🤖 Copilot prompt (Log-IQR):**  \n",
    "- *What is winsorizing in simple terms?*\n",
    "- *What is log transformation in simple terms?* \n",
    "- *Explain why computing IQR on the **log scale** produces a more stable upper cap for right-skewed hair concentrations than IQR on the raw scale.*\n",
    "\n",
    "---\n",
    "\n",
    "### 2) **Log-P99.5** (99.5th percentile on log values)\n",
    "- **What it is:** The 99.5th percentile of `log1p(x)`, back-transformed to raw scale.\n",
    "- **When to prefer:** You want a **quantile-based** cutoff that resists a few extreme points; useful in larger samples.\n",
    "- **Pros:** Simple to explain; insensitive to single outliers; scales naturally with sample size.\n",
    "- **Cons:** In small samples, the 99.5th percentile can be unstable; in heavily right-skewed data it may still be high.\n",
    "\n",
    "**🤖 Copilot prompt (Log-P99.5):**  \n",
    "*“List one benefit and one risk of using a fixed high quantile (like 99.5%) as an outlier cap for hair tox data. Keep it to two bullet points.”*\n",
    "\n",
    "---\n",
    "\n",
    "### 3) **Min of (Log-IQR upper, Log-P99.5)** (more conservative)\n",
    "- **What it is:** Compute both caps on the log scale, **choose the smaller** (stricter) cap, then back-transform.\n",
    "- **When to prefer:** You want a **conservative** rule that avoids leaving a very long tail; good default for teaching/assignments.\n",
    "- **Pros:** Tames heavy tails without being arbitrary; balances dispersion-based and quantile-based logic.\n",
    "- **Cons:** Can be **too aggressive** in small or already-trimmed samples, slightly shrinking valid high values.\n",
    "\n",
    "**🤖 Copilot prompt (Min-of-Both):**  \n",
    "*“In one paragraph, argue why the min-of-both rule can be a safer default for teaching analyses than either IQR-only or P99.5-only.”*\n",
    "\n",
    "---\n",
    "\n",
    "### 4) **None** (no cap; analyze on log scale only)\n",
    "- **What it is:** Keep raw values as is; do not cap. You may still **analyze** on the transformed scale (e.g., `*_log`) without winsorizing.\n",
    "- **When to prefer:** Exploratory work, very small samples, or when outlier handling is deferred to domain review.\n",
    "- **Pros:** No modification to raw scale; maximal transparency.\n",
    "- **Cons:** Extremes can dominate summaries; harder to compare “before vs after”.\n",
    "\n",
    "**🤖 Copilot prompt (None):**  \n",
    "*“Write two sentences explaining when it is reasonable to avoid winsorization and rely on log-scale modeling only.”*\n",
    "\n",
    "---\n",
    "\n",
    "## Tier B — Literature “upper” (audit only, **not** the operational cap)\n",
    "\n",
    "We also compute an analyte-specific **literature upper** and flag values above it with `*_plaus_flag` for **human review** (e.g., potential unit errors, contamination, or collection anomalies). This **does not** determine the applied cap; it’s an **audit trail** and teaching prompt.\n",
    "\n",
    "**🤖 Copilot prompt (Plausibility):**  \n",
    "*“Differentiate in 2–3 sentences between a **robust, sample-specific cap** and a **literature upper**. Which one do we use to modify data and why?”*\n",
    "\n",
    "---\n",
    "\n",
    "## Decision tips (how to choose)\n",
    "\n",
    "- If you want a solid default for skewed toxicology data: **Min-of-Both** (conservative, transparent).\n",
    "- If your sample is large and tails look noisy: **Log-P99.5** (stable quantile).\n",
    "- If you want a classic robust rule: **Log-IQR upper** (teachable, dispersion-aware).\n",
    "- If you’re exploring and documenting rather than modifying: **None** (use log transforms for modeling; keep flags for review).\n",
    "\n",
    "**🤖 Copilot prompt (Choosing a rule):**  \n",
    "*“Given my histogram and the candidate caps (IQR, P99.5, Min-of-Both), recommend one cap and justify the choice in ≤3 sentences, referencing tail length and the number of flagged values.”*\n",
    "\n",
    "---\n",
    "\n",
    "## Implementation notes\n",
    "\n",
    "- Outlier handling happens in **`df_out`**. We add:\n",
    "  - `*_wz` — winsorized at the chosen cap (if you selected a capping approach).\n",
    "  - `*_log` — transformed series (e.g., `log1p`) for visualization/modeling.\n",
    "  - `*_plaus_flag` — 1 if value exceeds literature upper; 0/NaN otherwise.\n",
    "- **Raw column is never overwritten** (provenance preserved). We’ll compare “before vs after” later.\n",
    "\n",
    "**🤖 Copilot prompt (Provenance):**  \n",
    "*“Explain why we keep raw, winsorized, and log versions as separate columns (`var`, `var_wz`, `var_log`) and how that supports before/after comparisons.”*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 — Setup (imports, DF hygiene, constants, helpers)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "FIG_DIR = Path(\"./figures\"); FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Expect df_raw to exist from your notebook intro; create df_out if missing\n",
    "if \"df_raw\" not in globals():\n",
    "    raise ValueError(\"df_raw not found. Load the raw dataset at the top of the notebook.\")\n",
    "if \"df_out\" not in globals():\n",
    "    df_out = df_raw.copy()\n",
    "\n",
    "# ABCD special codes → NaN (includes 666=QNS not evaluable)\n",
    "SPECIAL_MISS = {777: np.nan, 888: np.nan, 999: np.nan, 666: np.nan}\n",
    "\n",
    "# Hair quantitative variables (extend if needed)\n",
    "HAIR_QNT_VARS = [\n",
    "    \"su_y_hairtox__rslt__opi__hc_qnt\",  # Hydrocodone\n",
    "    \"su_y_hairtox__rslt__opi__cod_qnt\", # Codeine\n",
    "    \"su_y_hairtox__rslt__opi__oc_qnt\",  # Oxycodone\n",
    "    \"su_y_hairtox__rslt__opi__mor_qnt\", # Morphine\n",
    "]\n",
    "\n",
    "# Literature \"upper\" for plausibility (pg/mg) — audit only\n",
    "LIT_UPPER = {\n",
    "    \"su_y_hairtox__rslt__opi__hc_qnt\": 15000,\n",
    "    \"su_y_hairtox__rslt__opi__cod_qnt\":20000,\n",
    "    \"su_y_hairtox__rslt__opi__oc_qnt\": 26000,\n",
    "    \"su_y_hairtox__rslt__opi__mor_qnt\":13000,\n",
    "}\n",
    "ANALYTE_LABEL = {\n",
    "    \"su_y_hairtox__rslt__opi__hc_qnt\":  \"Hydrocodone\",\n",
    "    \"su_y_hairtox__rslt__opi__cod_qnt\": \"Codeine\",\n",
    "    \"su_y_hairtox__rslt__opi__oc_qnt\":  \"Oxycodone\",\n",
    "    \"su_y_hairtox__rslt__opi__mor_qnt\": \"Morphine\",\n",
    "}\n",
    "\n",
    "LOD, LOQ = 20, 40  # ABCD vendor thresholds in pg/mg\n",
    "\n",
    "def _num_clean(s):\n",
    "    return pd.to_numeric(s, errors=\"coerce\").replace(SPECIAL_MISS)\n",
    "\n",
    "def _log(s, base=\"log1p\"):\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    if base == \"log10\":\n",
    "        s = s.replace(0, np.nan)\n",
    "        return np.log10(s)\n",
    "    return np.log1p(s)\n",
    "\n",
    "def compute_caps(series, log_base=\"log1p\"):\n",
    "    \"\"\"Return dict with log-IQR upper, log-P99.5, min-of-both, and lit upper.\"\"\"\n",
    "    xlog = _log(series, log_base)\n",
    "    q1, q3 = xlog.quantile([.25, .75])\n",
    "    iqr = q3 - q1\n",
    "    iqr_upper = q3 + 1.5*iqr\n",
    "    p995 = xlog.quantile(.995)\n",
    "    # back-transform\n",
    "    to_raw = (np.expm1 if log_base==\"log1p\" else (lambda z: 10**z))\n",
    "    caps = {\n",
    "        \"log_iqr_upper\": float(to_raw(iqr_upper)),\n",
    "        \"log_p995\": float(to_raw(p995)),\n",
    "        \"min_of_both\": float(to_raw(min(iqr_upper, p995))),\n",
    "    }\n",
    "    return caps\n",
    "\n",
    "def winsorize_upper(series, cap):\n",
    "    s = pd.to_numeric(series, errors=\"coerce\")\n",
    "    return s.clip(upper=cap)\n",
    "\n",
    "def summarize_raw_wz_log(s_raw, s_wz, s_log):\n",
    "    def stats(s):\n",
    "        s = pd.to_numeric(s, errors=\"coerce\")\n",
    "        return pd.Series({\n",
    "            \"n\": len(s),\n",
    "            \"n_missing\": int(s.isna().sum()),\n",
    "            \"pct_missing\": s.isna().mean()*100,\n",
    "            \"mean\": s.mean(),\n",
    "            \"median\": s.median(),\n",
    "            \"sd\": s.std(),\n",
    "            \"p95\": s.quantile(.95),\n",
    "            \"p99\": s.quantile(.99),\n",
    "        })\n",
    "    return pd.concat(\n",
    "        [stats(s_raw).rename(\"raw\"), stats(s_wz).rename(\"winsorized\"), stats(s_log).rename(\"log_scale\")],\n",
    "        axis=1\n",
    "    ).round(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 1.2 — Pick ONE variable and preview it\n",
    "\n",
    "1) Set `SELECT_QNT` to one of the hair quantitative variables. \n",
    " \n",
    "**Pick one analyte variable:**\n",
    "- `su_y_hairtox__rslt__opi__hc_qnt` (Hydrocodone; upper 15,000 pg/mg)\n",
    "- `su_y_hairtox__rslt__opi__oc_qnt` (Oxycodone; upper 10,000 pg/mg)\n",
    "- `su_y_hairtox__rslt__opi__cod_qnt` (Codeine; upper 20,000 pg/mg)\n",
    "- `su_y_hairtox__rslt__opi__mor_qnt` (Morphine; upper 13,000 pg/mg)\n",
    "2) This cell cleans special codes, prints quick stats, and draws raw vs log histograms (no capping yet).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2A — STUDENT TODO: choose a variable to analyze\n",
    "# Set to ONE of: HAIR_QNT_VARS\n",
    "SELECT_QNT = ___  # <-- CHANGE THIS if you want a different analyte\n",
    "\n",
    "assert SELECT_QNT in HAIR_QNT_VARS, f\"SELECT_QNT must be one of {HAIR_QNT_VARS}\"\n",
    "assert SELECT_QNT in df_out.columns, f\"{SELECT_QNT} not found in df_out columns.\"\n",
    "\n",
    "label = ANALYTE_LABEL.get(SELECT_QNT, SELECT_QNT)\n",
    "s_raw = _num_clean(df_out[SELECT_QNT])\n",
    "\n",
    "print(f\"Analyte: {label} | Variable: {SELECT_QNT}\")\n",
    "display(s_raw.dropna().describe(percentiles=[.25,.5,.75]).to_frame().T)\n",
    "\n",
    "# quick raw + log hist (no caps yet)\n",
    "fig, ax = plt.subplots(1,2, figsize=(10,4))\n",
    "ax[0].hist(s_raw.dropna(), bins=30, edgecolor=\"black\")\n",
    "ax[0].set_title(\"Raw\"); ax[0].set_xlabel(\"pg/mg\"); ax[0].set_ylabel(\"Count\")\n",
    "xlog = _log(s_raw, \"log1p\").dropna()\n",
    "ax[1].hist(xlog, bins=30, edgecolor=\"black\")\n",
    "ax[1].set_title(\"Log1p\"); ax[1].set_xlabel(\"log1p(pg/mg)\"); ax[1].set_ylabel(\"Count\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 1.3 — See your options (caps & counts)\n",
    "\n",
    "We compute **all** candidate caps and show how many observations exceed each.  \n",
    "This is where you **learn the options** before choosing one to apply.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3A — Compute candidate caps + over-counts\n",
    "\n",
    "caps = compute_caps(s_raw, log_base=\"log1p\")  # we teach on log1p by default\n",
    "lit = LIT_UPPER.get(SELECT_QNT, np.inf)\n",
    "\n",
    "over = {\n",
    "    \"log_iqr_upper\": int(s_raw.gt(caps[\"log_iqr_upper\"]).sum()),\n",
    "    \"log_p995\":      int(s_raw.gt(caps[\"log_p995\"]).sum()),\n",
    "    \"min_of_both\":   int(s_raw.gt(caps[\"min_of_both\"]).sum()),\n",
    "    \"literature\":    int(s_raw.gt(lit).sum()) if np.isfinite(lit) else 0,\n",
    "}\n",
    "\n",
    "caps_tbl = pd.DataFrame({\n",
    "    \"cap_value\": [caps[\"log_iqr_upper\"], caps[\"log_p995\"], caps[\"min_of_both\"], lit],\n",
    "    \"n_above\":   [over[\"log_iqr_upper\"], over[\"log_p995\"], over[\"min_of_both\"], over[\"literature\"]],\n",
    "}, index=[\"log_iqr_upper\",\"log_p995\",\"min_of_both\",\"literature_upper\"]).round(2)\n",
    "\n",
    "display(caps_tbl)\n",
    "\n",
    "print(\"Interpretation guide:\")\n",
    "print(\"- log_iqr_upper: classic Tukey fence on log scale (robust).\")\n",
    "print(\"- log_p995: top 0.5% cutoff on log scale (robust, quantile-based).\")\n",
    "print(\"- min_of_both: conservative cap (choose the smaller cap).\")\n",
    "print(\"- literature_upper: audit only; use to flag plausibility, not as the applied cap.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 1.4 — Choose ONE approach and apply it\n",
    "\n",
    "We make **two separate decisions** here:  \n",
    "\n",
    "- **APPROACH** = the rule for **defining the cap value** (Tier A). This is how you decide the threshold for “high” values.  \n",
    "  Examples:  \n",
    "  - `\"log_iqr_upper\"` → Tukey fence (Q3 + 1.5×IQR) on the log scale.  \n",
    "  - `\"log_p995\"` → 99.5th percentile on the log scale.  \n",
    "  - `\"min_of_both\"` → more conservative (smaller) of the two above.  \n",
    "  - `\"none\"` → skip calculating/applying any robust cap.\n",
    "\n",
    "- **ACTION** = what you actually **do** with that cap once chosen. In this lab, we will **always winsorize** values above the chosen cap in `df_out` (Tier A) while keeping the original values intact in `df_raw`.  \n",
    "  Examples in other contexts might include `\"transform_only\"` (log scale, no capping) or `\"none\"` (no change).\n",
    "\n",
    "We will also always add a **plausibility flag** for values above the **literature upper** (Tier B), even if no winsorizing is done. This ensures you can identify results that may be implausible given known toxicology ranges.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4A — STUDENT TODO: choose your approach and action\n",
    "APPROACH = ___   # <-- CHANGE to \"log_iqr_upper\" | \"log_p995\" | \"min_of_both\" | \"none\"\n",
    "ACTION   = ___      # <-- \"winsorize\" | \"transform_only\" | \"none\"\n",
    "\n",
    "assert APPROACH in {\"log_iqr_upper\",\"log_p995\",\"min_of_both\",\"none\"}\n",
    "assert ACTION in {\"winsorize\",\"transform_only\",\"none\"}\n",
    "\n",
    "# pick cap\n",
    "chosen_cap = np.inf if APPROACH==\"none\" else caps[APPROACH]\n",
    "\n",
    "# materialize *_wz and *_log columns in df_out (do not overwrite original)\n",
    "if ACTION == \"winsorize\" and np.isfinite(chosen_cap):\n",
    "    s_wz = winsorize_upper(s_raw, chosen_cap)\n",
    "else:\n",
    "    s_wz = s_raw.copy()\n",
    "\n",
    "s_log = _log(s_raw, \"log1p\")  # we report log1p summaries for skew\n",
    "\n",
    "df_out[SELECT_QNT + \"_wz\"]  = s_wz\n",
    "df_out[SELECT_QNT + \"_log\"] = s_log\n",
    "\n",
    "# plausibility flag (always calculated if literature upper available)\n",
    "if np.isfinite(lit):\n",
    "    df_out[SELECT_QNT + \"_plaus_flag\"] = (s_raw > lit).astype(\"Int64\")\n",
    "\n",
    "print(f\"Applied approach: {APPROACH} | ACTION: {ACTION}\")\n",
    "print(f\"Chosen robust cap (pg/mg): {'∞' if not np.isfinite(chosen_cap) else round(chosen_cap,2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 1.5 — Before/After summaries (raw vs winsorized vs log)\n",
    "\n",
    "Check how your choice impacts the distribution. We also report how many values exceed your **chosen cap** and the **literature upper**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5A — Summary table + counts\n",
    "\n",
    "summary_tbl = summarize_raw_wz_log(s_raw, df_out[SELECT_QNT + \"_wz\"], df_out[SELECT_QNT + \"_log\"])\n",
    "display(summary_tbl)\n",
    "\n",
    "n_over_cap = int(s_raw.gt(chosen_cap).sum()) if np.isfinite(chosen_cap) else 0\n",
    "n_over_lit = int(s_raw.gt(lit).sum()) if np.isfinite(lit) else 0\n",
    "print(f\"Values > chosen robust cap: {n_over_cap}\")\n",
    "print(f\"Values > literature upper (plausibility): {n_over_lit}\")\n",
    "\n",
    "# Save summary\n",
    "out_csv = FIG_DIR / f\"{SELECT_QNT}_outlier_summary_{APPROACH}.csv\"\n",
    "summary_tbl.to_csv(out_csv)\n",
    "print(f\"Saved: {out_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 1.6 — Visuals with markers\n",
    "\n",
    "Two quick visuals:\n",
    "\n",
    "1) **Raw scale** with vertical lines at **LOD=20**, **LOQ=40**, **literature upper**, and **chosen robust cap**.  \n",
    "2) **Log scale** histograms **before vs after** winsorizing.\n",
    "\n",
    "These make it obvious how your choice changes the tail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.6A — Plots\n",
    "\n",
    "vals = s_raw.dropna()\n",
    "if not vals.empty:\n",
    "    # Raw scale\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.hist(vals, bins=30, edgecolor=\"black\")\n",
    "    ymax = plt.ylim()[1]\n",
    "    markers = [(LOD,\"LOD\"), (LOQ,\"LOQ\")]\n",
    "    if np.isfinite(lit): markers.append((lit,\"Literature upper\"))\n",
    "    if np.isfinite(chosen_cap): markers.append((chosen_cap,\"Chosen robust cap\"))\n",
    "    for v, lbl in markers:\n",
    "        plt.axvline(v, linestyle=\"--\")\n",
    "        plt.text(v, ymax*0.9, lbl, rotation=90, va=\"top\")\n",
    "    plt.title(f\"{ANALYTE_LABEL.get(SELECT_QNT, SELECT_QNT)} — Raw (pg/mg)\")\n",
    "    plt.xlabel(\"Concentration (pg/mg)\"); plt.ylabel(\"Count\")\n",
    "    plt.tight_layout()\n",
    "    p1 = FIG_DIR / f\"{SELECT_QNT}_raw_hist_{APPROACH}.png\"\n",
    "    plt.savefig(p1); plt.show(); print(f\"Saved: {p1}\")\n",
    "\n",
    "    # Log scale before vs after\n",
    "    raw_log = _log(s_raw, \"log1p\").dropna()\n",
    "    wz_log  = _log(df_out[SELECT_QNT + \"_wz\"], \"log1p\").dropna()\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.hist(raw_log, bins=30, alpha=0.7, label=\"Before (raw)\", edgecolor=\"black\")\n",
    "    plt.hist(wz_log,  bins=30, alpha=0.7, label=\"After (winsorized)\", edgecolor=\"black\")\n",
    "    plt.title(f\"{ANALYTE_LABEL.get(SELECT_QNT, SELECT_QNT)} — Log (Before vs After)\")\n",
    "    plt.xlabel(\"log1p(pg/mg)\"); plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    p2 = FIG_DIR / f\"{SELECT_QNT}_log_hist_before_after_{APPROACH}.png\"\n",
    "    plt.savefig(p2); plt.show(); print(f\"Saved: {p2}\")\n",
    "else:\n",
    "    print(\"No non-missing values to plot.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 1.8 — Your Reflection (3–5 sentences)\n",
    "\n",
    "- Name the **analyte** you worked on and the **approach you chose** (`log_iqr_upper`, `log_p995`, `min_of_both`, or `none`).  \n",
    "- Report how many values exceeded your **chosen robust cap** and the **literature upper**.  \n",
    "- Explain **why** your choice is appropriate for right-skewed hair data (why log? why this cap?).  \n",
    "- Clarify that literature is a **plausibility flag**, not your operational cap.  \n",
    "- Optional: If you try a different approach, do your conclusions change?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "# 2.0 Inconsistencies: Discordance (Self-Report vs Hair Screen)\n",
    "\n",
    "**Goal:** Build a simple **discordance flag** using only:\n",
    "- **Past-year self-report** `su_y_sui__use__rxopi_001__l` (0 = denies use, 1 = yes)\n",
    "- **Hair toxicology screen** `su_y_hairtox__rslt__opi_scrn` (0/1; **666 = QNS**)\n",
    "\n",
    "**Definition (primary discordance):** `self-report == 0` **AND** `hair screen == 1` → flag = **1**  \n",
    "This highlights cases where reported non-use conflicts with a positive screen.\n",
    "\n",
    "**Data hygiene for this section**\n",
    "- Convert ABCD special codes **777/888/999 → NaN** (not data).  \n",
    "- Treat hair **666 (QNS) → NaN** (not evaluable; do not count as negative).\n",
    "\n",
    "**What you’ll do in the TODO cell**\n",
    "1. Fill in `SR_VAR` and `HAIR_VAR` with the exact column names above.  \n",
    "2. Create `discordant_sr_no_hair_pos = 1` when **SR = 0** and **Hair = 1** (else 0/NA).  \n",
    "3. Produce a **summary table** for SR, Hair, and the Discordant flag (n, missing %, n=1/n=0 of evaluable).  \n",
    "4. Report **evaluable pairs (both present)** and **% discordant**.  \n",
    "5. Draw a **plain-language bar chart** with three counts:  \n",
    "   - “Discordant: Denied use + Hair positive”  \n",
    "   - “Hair screen: Positive”  \n",
    "   - “Self-report (past year): Yes”\n",
    "\n",
    "**Why this matters (interpretation cues)**\n",
    "- **Time window:** Hair ≈ past 1–3 months; SR is past year. SR-Yes + Hair-No can be a window mismatch.  \n",
    "- **Screen vs confirm:** Screen positives may lack confirm/quant; QNS isn’t negative.  \n",
    "- **Analysis choices:** You’ll later debate treating discordance as a covariate, using a conservative combine rule, or excluding discordant cases.\n",
    "\n",
    "---\n",
    "\n",
    "### 🤖 Copilot Prompts (use one at a time)\n",
    "\n",
    "- *Explain in 3–4 sentences what “discordant (SR=0 & Hair=1)” means and why hair’s shorter detection window matters for interpretation.*  \n",
    "- *Given the summary table (n, % missing, n₁/n₀) and the evaluable-pairs denominator, describe the discordance rate without quoting raw counts.*    \n",
    "- *If the discordance rate were **~25%**, list two defensible handling strategies and one risk for each (bias vs. variance).*  \n",
    "- *Draft a one-sentence caption that distinguishes “plausibility” (QNS/confirm issues) from “true disagreement” between measures.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Build discordant flag, summarize, and plot (plain-language labels)\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Paths & constants ---\n",
    "FIG_DIR = Path(\"./figures\")\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "SR_VAR   = ___       # TODO: Insert self-report (past year): 0/1\n",
    "HAIR_VAR = ___       # TODO: Insert hair screen: 0/1 (666=QNS)\n",
    "SPECIAL_MISS = {777: np.nan, 888: np.nan, 999: np.nan}\n",
    "\n",
    "# --- Guard for required columns ---\n",
    "missing_cols = [c for c in [SR_VAR, HAIR_VAR] if c not in df_raw.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing required column(s): {missing_cols}\")\n",
    "\n",
    "# --- Prepare data (standardize missing; hair QNS=666 -> NaN) ---\n",
    "tmp = df_raw[[SR_VAR, HAIR_VAR]].copy().replace(SPECIAL_MISS)\n",
    "tmp[SR_VAR]   = pd.to_numeric(tmp[SR_VAR], errors=\"coerce\")          # 0/1/NaN\n",
    "tmp[HAIR_VAR] = pd.to_numeric(tmp[HAIR_VAR], errors=\"coerce\").replace({666: np.nan})  # 0/1/NaN\n",
    "\n",
    "sr   = tmp[SR_VAR]\n",
    "hair = tmp[HAIR_VAR]\n",
    "\n",
    "# --- Discordant flag: Denied use (0) AND Hair positive (1) ---\n",
    "discordant = ((sr == ___) & (hair == ___)).astype(\"Int64\")   # TODO: Define values of sr and hair variables that define discordance\n",
    "tmp[\"discordant_sr_no_hair_pos\"] = discordant\n",
    "\n",
    "# --- Summary stats helper (binary with NA) ---\n",
    "def summarize_binary(s: pd.Series, label: str) -> pd.Series:\n",
    "    n = len(s)\n",
    "    n_missing = int(s.isna().sum())\n",
    "    n_eval = n - n_missing\n",
    "    n1 = int((s == 1).sum())\n",
    "    n0 = int((s == 0).sum())\n",
    "    return pd.Series({\n",
    "        \"label\": label,\n",
    "        \"n\": n,\n",
    "        \"n_evaluable\": n_eval,\n",
    "        \"n_missing\": n_missing,\n",
    "        \"pct_missing\": (n_missing/n*100) if n else np.nan,\n",
    "        \"n_1\": n1,\n",
    "        \"pct_1_of_evaluable\": (n1/n_eval*100) if n_eval else np.nan,\n",
    "        \"n_0\": n0,\n",
    "        \"pct_0_of_evaluable\": (n0/n_eval*100) if n_eval else np.nan\n",
    "    })\n",
    "\n",
    "# --- Build summary table for SR, Hair, and the Discordant flag ---\n",
    "summary = pd.concat([\n",
    "    summarize_binary(sr,   \"Self-report (past year): Yes=1, No=0\"),\n",
    "    summarize_binary(hair, \"Hair screen: Positive=1, Negative=0\"),\n",
    "    summarize_binary(discordant, \"Discordant: Denied use + Hair positive (flag=1)\")\n",
    "], axis=1).T\n",
    "\n",
    "# Evaluable pair denominator and discordance %\n",
    "evaluable_pairs = (~sr.isna()) & (~hair.isna())\n",
    "n_pairs = int(evaluable_pairs.sum())\n",
    "n_discordant = int(((sr == 0) & (hair == 1) & evaluable_pairs).sum())\n",
    "pct_discordant_pairs = (n_discordant/n_pairs*100) if n_pairs else np.nan\n",
    "\n",
    "print(\"Summary table (saved to ./figures/discordance_summary_stats.csv):\")\n",
    "display(summary.round(3))\n",
    "print(f\"\\nEvaluable pairs (both present): {n_pairs}\")\n",
    "print(f\"Primary discordance (Denied use + Hair positive): {n_discordant} \"\n",
    "      f\"({pct_discordant_pairs:.2f}% of evaluable pairs)\")\n",
    "\n",
    "summary.to_csv(FIG_DIR / \"discordance_summary_stats.csv\", index=False)\n",
    "\n",
    "# --- Plain-language bar chart: counts of Discordant vs Hair Positive vs SR Yes ---\n",
    "labels = [\n",
    "    \"Discordant: Denied use + Hair positive\",\n",
    "    \"Hair screen: Positive\",\n",
    "    \"Self-report (past year): Yes\"\n",
    "]\n",
    "counts = [\n",
    "    n_discordant,\n",
    "    int((hair == 1).sum()),\n",
    "    int((sr == 1).sum())\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.bar(labels, counts)\n",
    "plt.ylabel(\"Number of participants\")\n",
    "plt.title(\"Counts: Discordant vs Hair Positive vs Self-Report Yes\")\n",
    "plt.xticks(rotation=20, ha=\"right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / \"discordance_counts_plain_labels.png\", dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 2. Your Turn\n",
    "\n",
    "Insert the **discordance bar figure** into your reflection file and write **2–3 sentences**:\n",
    "  - State the discordant count and % of evaluable cases.\n",
    "  - Choose one handling rule—**keep a discordance covariate** (flag cases for adjustment in models), **conservative combine** (treat any “Yes” from self-report OR toxicology as use), or **exclude discordant cases** (remove from analysis entirely)—and explain why you would take this approach in the context of your research question. In your justification, address the trade-offs: how your choice affects sample size, bias, and interpretability; whether the decision leans toward minimizing false negatives, preserving validity of self-reported patterns, or avoiding measurement conflict altogether.\n",
    "  - In real studies, discordance rates can be in the 15-20% range, imagine your data showed 25 percent discordance, would you take the same handling approach?\n",
    "  - In both cases, discordance shows that self-report data always has some underreport error, how does this effect your analysis of substance use data?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 3.0 — Orientation\n",
    "\n",
    "**Part 3 — Missingness, Imputation, and Composite EDA**  \n",
    "In this section, we will:  \n",
    "1. Map missingness across the dataset.  \n",
    "2. Audit three variable groups to understand *why* values are missing.  \n",
    "3. Perform row-wise MCAR imputation for the peer items and then repeat the composite EDA from Lab 2.\n",
    "\n",
    "**Groups we’ll examine:**\n",
    "- **Hair toxicology** — patterns from collection procedures, `QNS=666`, and selective confirm/quant tests.  \n",
    "- **SUI follow-ups** — asked only if prior “gate” variables are on (structured skips).  \n",
    "- **Peer items** — `PBP 001–003`, `PGD 001–009`, plus `fc_y_pm_mean`; assume ≈5% MCAR.\n",
    "\n",
    "**Deliverables from this section:**\n",
    "- Missingness heatmap (`.png`)  \n",
    "- Three summary tables (hair tox, SUI follow-ups, peer items)  \n",
    "- “Before vs After” figures for PBP and PGD composites saved in `./figures/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "FIG_DIR = Path(\"./figures\"); FIG_DIR.mkdir(exist_ok=True)\n",
    "SPECIAL_MISS = {777: np.nan, 888: np.nan, 999: np.nan}  # course standard\n",
    "\n",
    "def existing(cols, df):\n",
    "    return [c for c in cols if c in df.columns]\n",
    "\n",
    "def missing_overview(df):\n",
    "    rate = df.isna().mean().sort_values(ascending=False)\n",
    "    return rate.to_frame(\"pct_missing\").assign(pct_missing=lambda x: x[\"pct_missing\"]*100)\n",
    "\n",
    "def code_aware_missing_summary(raw_df, cols, extra_codes=(666,)):\n",
    "    \"\"\"Summarize NaN and special code counts for selected columns (use RAW df to count codes).\"\"\"\n",
    "    cols = existing(cols, raw_df)\n",
    "    rows, n = [], len(raw_df)\n",
    "    for c in cols:\n",
    "        s_raw = raw_df[c]\n",
    "        row = {\n",
    "            \"variable\": c,\n",
    "            \"n\": n,\n",
    "            \"n_nan\": int(pd.to_numeric(s_raw, errors=\"coerce\").isna().sum()),\n",
    "            \"pct_nan\": pd.to_numeric(s_raw, errors=\"coerce\").isna().mean()*100,\n",
    "        }\n",
    "        for code in extra_codes:\n",
    "            n_code = int((s_raw == code).sum())\n",
    "            row[f\"n_{code}\"] = n_code\n",
    "            row[f\"pct_{code}\"] = (n_code/n)*100\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows).sort_values(\"pct_nan\", ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## 3.2 — Heatmap of Missingness (Top 40 Columns)\n",
    "\n",
    "We first standardize ABCD missing codes (`777`, `888`, `999` → `NaN`).  \n",
    "For **hair toxicology** variables only, we also treat `666` (*Quantity Not Sufficient*, QNS) as missing for visualization purposes — but we will still report it as a special code in our summary table.\n",
    "\n",
    "Then, we generate a heatmap of the **top 40 columns by % missing** and save it as a `.png` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and standardize\n",
    "df_heat = df_out.copy().replace(SPECIAL_MISS)\n",
    "\n",
    "# Hair tox columns (declare once; used again below)\n",
    "hair_cols = [\n",
    "    \"su_y_hairtox__coll_002\",\n",
    "    \"su_y_hairtox__lab_len\",\n",
    "    \"su_y_hairtox__lab_weight\",\n",
    "    \"su_y_hairtox__rslt__opi_scrn\",\n",
    "    \"su_y_hairtox__rslt__opi__hc_cnf\",\n",
    "    \"su_y_hairtox__rslt__opi__hc_qnt\",\n",
    "    \"su_y_hairtox__rslt__opi__oc_cnf\",\n",
    "    \"su_y_hairtox__rslt__opi__oc_qnt\",\n",
    "    \"su_y_hairtox__rslt__opi__cod_cnf\",\n",
    "    \"su_y_hairtox__rslt__opi__cod_qnt\",\n",
    "    \"su_y_hairtox__rslt__opi__mor_cnf\",\n",
    "    \"su_y_hairtox__rslt__opi__mor_qnt\",\n",
    "]\n",
    "hair_cols = existing(hair_cols, df_heat)\n",
    "\n",
    "# Treat QNS=666 as NaN for hair tox visualization\n",
    "for c in hair_cols:\n",
    "    df_heat[c] = pd.to_numeric(df_heat[c], errors=\"coerce\").replace({666: np.nan})\n",
    "\n",
    "# Top 40 columns by missing rate\n",
    "top_cols = missing_overview(df_heat).head(40).index\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df_heat[top_cols].isna(), cbar=False, cmap=\"binary\")\n",
    "plt.title(\"Missingness Heatmap — Top 40 Columns (black = missing)\")\n",
    "plt.xlabel(\"Columns\"); plt.ylabel(\"Rows\")\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / \"missing_heatmap_top40.png\", dpi=200); plt.show()\n",
    "\n",
    "# Save overall table for reference\n",
    "missing_overview(df_heat).to_csv(FIG_DIR / \"missing_rate_all_columns.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "## 3.3 — Interpreting the Heatmap: MCAR, MAR, MNAR\n",
    "\n",
    "Use the heatmap to identify patterns of missingness:\n",
    "\n",
    "- **MCAR** (*Missing Completely at Random*): Appears patternless; safe for simple methods such as row-wise mean/median imputation within a small, related block of variables.  \n",
    "- **MAR** (*Missing At Random*): Missingness can be explained by other observed variables (e.g., hair not collected at remote visits; lab confirm tests only run on screens/priority panels).  \n",
    "- **MNAR** (*Missing Not At Random*): Missingness depends on the unobserved value itself (e.g., youths less likely to disclose in follow-ups when use is heavier).\n",
    "\n",
    "We’ll now audit three variable groups for missingness patterns and potential mechanisms:  \n",
    "1. **Hair toxicology**  \n",
    "2. **SUI follow-ups**  \n",
    "3. **Peer variables**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Group definitions ---\n",
    "# 1) Hair tox: use explicit list from above (already filtered)\n",
    "hair_cols = existing(hair_cols, df_raw)\n",
    "\n",
    "# 2) SUI follow-ups: discover by prefix (keeps this robust to column set)\n",
    "sui_fw_cols = sorted([c for c in df_raw.columns if c.startswith(\"su_y_sui__rxopi__fwup_\")])\n",
    "\n",
    "# 3) Peer variables: pbp, pgd, and fc_y_pm_mean\n",
    "pbp_items = existing([\"fc_y_pbp_001\",\"fc_y_pbp_002\",\"fc_y_pbp_003\"], df_raw)\n",
    "pgd_items = existing([\n",
    "    \"su_y_pgd_001\",\"su_y_pgd_002\",\"su_y_pgd_003\",\"su_y_pgd_004\",\n",
    "    \"su_y_pgd_005\",\"su_y_pgd_006\",\"su_y_pgd_007\",\"su_y_pgd_008\",\"su_y_pgd_009\"\n",
    "], df_raw)\n",
    "peer_extra = existing([\"fc_y_pm_mean\"], df_raw)\n",
    "peer_cols = pbp_items + pgd_items + peer_extra\n",
    "\n",
    "# Summaries (use RAW df to count special codes; treat 666 as special for hair tox)\n",
    "hair_tbl = code_aware_missing_summary(df_raw, hair_cols, extra_codes=(666,777,888,999))\n",
    "sui_tbl  = code_aware_missing_summary(df_raw, sui_fw_cols, extra_codes=(777,888,999))\n",
    "peer_tbl = code_aware_missing_summary(df_raw, peer_cols, extra_codes=(777,888,999))\n",
    "\n",
    "display(hair_tbl.head(12))\n",
    "display(sui_tbl.head(12))\n",
    "display(peer_tbl.head(12))\n",
    "\n",
    "hair_tbl.to_csv(FIG_DIR / \"missing_summary_hairtox.csv\", index=False)\n",
    "sui_tbl.to_csv(FIG_DIR / \"missing_summary_sui_followups.csv\", index=False)\n",
    "peer_tbl.to_csv(FIG_DIR / \"missing_summary_peer.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "## 3.5 — What to Write\n",
    "\n",
    "**Short write-up (3–5 bullets):**\n",
    "- Name **2–3 hair tox variables** with high % `NaN` and/or `666` (QNS); explain why this is expected based on collection patterns and selective confirm/quant testing.  \n",
    "  *Reference:* [ABCD Hair Toxicology Documentation](https://docs.abcdstudy.org/latest/documentation/non_imaging/su.html#su_y_hairtox)  \n",
    "- Name **2–3 SUI follow-up variables** with high missingness; explain that these are *structured skips* — asked only if a prior gate variable is “on.”  \n",
    "- Name **2–3 peer variables** and explain why these appear closer to MCAR (small, random holes without clear dependency on other variables).  \n",
    "- State which group(s) you would **never impute naïvely** (hair tox, SUI follow-ups) and which you **would** impute (peer). Include one sentence justification for each choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## 3.6 — MCAR Imputation (Row-wise Mean): Why, When, and How\n",
    "\n",
    "In Part 3 we treat the **peer variables** as having ~5% **MCAR** (Missing Completely At Random): the chance a value is missing does **not** depend on the value itself or other measured fields in a systematic way. Under MCAR, simple, local fixes are acceptable because they don’t introduce directional bias.\n",
    "\n",
    "**Row-wise mean imputation** fills a missing item for a participant using the **mean of the other items in the same row** (i.e., their own responses within a small, coherent block such as PBP/PGD). This keeps a person’s scale scores on their own response “profile,” instead of borrowing from group averages. It’s intentionally simple so you can see **before vs after** effects when you rebuild composites.\n",
    "\n",
    "Guidelines:\n",
    "- Use a **small, conceptually tight block** (here: PBP 001–003, PGD 001–009, plus `fc_y_pm_mean`).\n",
    "- Convert ABCD special codes → `NaN` (we use `777/888/999 → NaN`).\n",
    "- Create **new** columns with a `*_imp` suffix; never overwrite originals.\n",
    "- Keep provenance: “before” = `df_out` (post-outliers), “after” = `df_imp` (imputed).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6 — Minimal core needed by 3.7/3.8 (MCAR row-wise mean + sum builders)\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# Ensure SPECIAL_MISS is defined (already done earlier, but safe to redefine)\n",
    "SPECIAL_MISS = {777: np.nan, 888: np.nan, 999: np.nan}\n",
    "\n",
    "# Start from outlier-cleaned data (df_out) and replace special codes\n",
    "df_imp = df_out.copy().replace(SPECIAL_MISS)\n",
    "\n",
    "# Item blocks\n",
    "pbp_items = [c for c in [\"fc_y_pbp_001\",\"fc_y_pbp_002\",\"fc_y_pbp_003\"] if c in df_imp.columns]\n",
    "pgd_items = [c for c in [f\"su_y_pgd_{i:03d}\" for i in range(1,10)] if c in df_imp.columns]\n",
    "peer_block = pbp_items + pgd_items + [c for c in [\"fc_y_pm_mean\"] if c in df_imp.columns]\n",
    "\n",
    "# Row-wise MEAN imputation (MCAR)\n",
    "block_num = df_imp[peer_block].apply(pd.to_numeric, errors=\"coerce\")\n",
    "row_mean = block_num.mean(axis=1, skipna=True)\n",
    "for c in peer_block:\n",
    "    df_imp[c + \"_imp\"] = pd.to_numeric(df_imp[c], errors=\"coerce\").fillna(row_mean)\n",
    "\n",
    "def build_sums_three_ways(df_before, df_after_imp, items, prefix):\n",
    "    items = [c for c in items if c in df_before.columns]\n",
    "\n",
    "    # BEFORE: replace special codes -> NaN, then compute strict & available\n",
    "    before_block = df_before[items].replace(SPECIAL_MISS)\n",
    "    before_num   = before_block.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    n_items = len(items)\n",
    "    strict = before_num.sum(axis=1, min_count=n_items)  # listwise\n",
    "    avail  = before_num.sum(axis=1, min_count=1)        # available-case\n",
    "\n",
    "    # AFTER: sum imputed items\n",
    "    after_num = df_after_imp[[c + \"_imp\" for c in items]].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    imp = after_num.sum(axis=1)\n",
    "\n",
    "    # attach to df_after_imp so downstream code can find them\n",
    "    df_after_imp[f\"{prefix}_sum_strict\"] = strict\n",
    "    df_after_imp[f\"{prefix}_sum_avail\"]  = avail\n",
    "    df_after_imp[f\"{prefix}_sum_imp\"]    = imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "## 3.7 — Demo: PBP Composite × DAPI (Before vs After Imputation)\n",
    "\n",
    "We’ll rebuild the **PBP** composite two ways:\n",
    "- **Before (strict/listwise)** from `df_out` → `pbp_sum_strict`\n",
    "- **After (imputed)** from `df_imp` → `pbp_sum_imp`\n",
    "\n",
    "Then we’ll compare each vs **DAPI** (`su_y_drgprob_prsum`) with:\n",
    "- scatter plots,\n",
    "- **Spearman’s rho**,\n",
    "- a standard readout of **n, mean, sd** for the PBP axis (pairwise complete with DAPI).\n",
    "\n",
    "Special codes `777/888/999 → NaN` are applied before any sums or correlations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.7A — Demo code (ready to run)\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure PBP sums exist (uses the 3.6 builder)\n",
    "if \"pbp_sum_strict\" not in df_imp.columns or \"pbp_sum_imp\" not in df_imp.columns:\n",
    "    build_sums_three_ways(df_out, df_imp, pbp_items, \"pbp\")\n",
    "\n",
    "# PBP before/after\n",
    "pbp_before = pd.to_numeric(df_imp[\"pbp_sum_strict\"], errors=\"coerce\")\n",
    "pbp_after  = pd.to_numeric(df_imp[\"pbp_sum_imp\"],    errors=\"coerce\")\n",
    "\n",
    "# DAPI (clean like Lab 2)\n",
    "dapi = pd.to_numeric(df_raw[\"su_y_drgprob_prsum\"], errors=\"coerce\")\n",
    "dapi = dapi.replace({777: np.nan, 888: np.nan, 999: np.nan})\n",
    "\n",
    "def pair_stats(x, y):\n",
    "    m = (~x.isna()) & (~y.isna())\n",
    "    return int(m.sum()), x[m].mean(), x[m].std()\n",
    "\n",
    "# BEFORE\n",
    "mask_b = (~pbp_before.isna()) & (~dapi.isna())\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(pbp_before[mask_b], dapi[mask_b], alpha=0.5)\n",
    "plt.title(\"PBP (strict) vs DAPI\"); plt.xlabel(\"PBP sum (strict)\"); plt.ylabel(\"DAPI sum\")\n",
    "try: savefig(\"3_7_pbp_strict_vs_dapi\"); \n",
    "except: pass\n",
    "plt.show()\n",
    "\n",
    "if mask_b.sum() > 1:\n",
    "    rho_b, p_b = spearmanr(pbp_before[mask_b], dapi[mask_b])\n",
    "    n_b, mu_b, sd_b = pair_stats(pbp_before, dapi)\n",
    "    print(f\"BEFORE — n={n_b}, mean={mu_b:.2f}, sd={sd_b:.2f}; Spearman rho={rho_b:.3f}, p={p_b:.3g}\")\n",
    "else:\n",
    "    print(\"BEFORE — Not enough complete pairs.\")\n",
    "\n",
    "# AFTER\n",
    "mask_a = (~pbp_after.isna()) & (~dapi.isna())\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(pbp_after[mask_a], dapi[mask_a], alpha=0.5)\n",
    "plt.title(\"PBP (imputed) vs DAPI\"); plt.xlabel(\"PBP sum (imputed)\"); plt.ylabel(\"DAPI sum\")\n",
    "try: savefig(\"3_7_pbp_imputed_vs_dapi\"); \n",
    "except: pass\n",
    "plt.show()\n",
    "\n",
    "if mask_a.sum() > 1:\n",
    "    rho_a, p_a = spearmanr(pbp_after[mask_a], dapi[mask_a])\n",
    "    n_a, mu_a, sd_a = pair_stats(pbp_after, dapi)\n",
    "    print(f\"AFTER  — n={n_a}, mean={mu_a:.2f}, sd={sd_a:.2f}; Spearman rho={rho_a:.3f}, p={p_a:.3g}\")\n",
    "else:\n",
    "    print(\"AFTER — Not enough complete pairs.\")\n",
    "\n",
    "# Sanity hint for students (PBP shouldn't be in the thousands)\n",
    "if (pbp_before.max(skipna=True) or 0) > 200 or (pbp_after.max(skipna=True) or 0) > 200:\n",
    "    print(\"Note: PBP looks unusually large. Ensure special codes were set to NaN before summing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### 🤖 Copilot prompts (3.7 Demo)\n",
    "- “Summarize how **n, mean, sd, rho** changed from BEFORE to AFTER without quoting numbers; say whether each increased, decreased, or was stable.”\n",
    "- “Give a one-sentence reason why Spearman is used for these composites instead of Pearson.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## 3.8 — Your Turn: PGD Composite × (Pick a Numeric Variable)\n",
    "\n",
    "**This task mirrors 3.7.** Use the 3.7 demo as your template: same workflow, same summary readout (**n, mean, sd, Spearman’s ρ**), just swapping in the **PGD composite** and a **numeric variable of your choice**.\n",
    "\n",
    "**What to do**\n",
    "1) Choose a numeric variable (e.g., `su_y_drgprob_prsum`, `fc_y_pm_mean`, `su_y_sui__rxopi__lt_001`, `su_y_sui__rxopi__onset_useage`).  \n",
    "2) Make sure PGD sums exist (`pgd_sum_strict`, `pgd_sum_imp`) using the builder from 3.6.  \n",
    "3) Plot **BEFORE (strict)** and **AFTER (imputed)** scatterplots with light transparency to reduce overplotting.  \n",
    "4) Compute **Spearman’s ρ** for both, and print a standard readout: **n, mean, sd, rho, p**.  \n",
    "5) Print a one‑liner: **Δn** and **Δρ** (imputed − strict).\n",
    "\n",
    "> Hint: If you get weirdly large PGD values, you probably didn’t convert special codes (777/888/999) to `NaN` **before** summing. The 3.6 builder already handles this—reuse it as in 3.7.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.8A — Your Turn (fill in the blanks; follow 3.7 as a guide)\n",
    "\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1) Choose the second numeric variable ---\n",
    "num2_var = \"___\"  # e.g., \"su_y_drgprob_prsum\" or \"fc_y_pm_mean\"\n",
    "\n",
    "# Clean special codes like 3.7\n",
    "num2 = pd.to_numeric(df_raw[num2_var], errors=\"coerce\")\n",
    "num2 = num2.replace({777: np.nan, 888: np.nan, 999: np.nan})\n",
    "\n",
    "# --- 2) Ensure PGD sums exist (built in 3.6) ---\n",
    "if \"pgd_sum_strict\" not in df_imp.columns or \"pgd_sum_imp\" not in df_imp.columns:\n",
    "    build_sums_three_ways(df_out, df_imp, pgd_items, \"pgd\")\n",
    "\n",
    "pgd_before = pd.to_numeric(df_imp[\"pgd_sum_strict\"], errors=\"coerce\")\n",
    "pgd_after  = pd.to_numeric(df_imp[\"pgd_sum_imp\"],    errors=\"coerce\")\n",
    "\n",
    "def pair_stats(x, y):\n",
    "    m = (~x.isna()) & (~y.isna())\n",
    "    return int(m.sum()), x[m].mean(), x[m].std(), m\n",
    "\n",
    "# --- 3) BEFORE scatter + stats ---\n",
    "n_b, mu_b, sd_b, mask_b = pair_stats(pgd_before, num2)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(pgd_before[mask_b], num2[mask_b], alpha=___)  # e.g., 0.5\n",
    "plt.title(f\"PGD (strict) vs ___\")                         # fill with num2_var\n",
    "plt.xlabel(\"___\")                                         # e.g., \"PGD sum (strict)\"\n",
    "plt.ylabel(\"___\")                                         # e.g., num2_var\n",
    "try: savefig(f\"3_8_pgd_strict_vs___\")                     # fill with num2_var\n",
    "except: pass\n",
    "plt.show()\n",
    "\n",
    "if n_b > 1:\n",
    "    rho_b, p_b = spearmanr(pgd_before[mask_b], num2[mask_b])\n",
    "    print(f\"BEFORE — n={n_b}, mean={mu_b:.2f}, sd={sd_b:.2f}; Spearman rho={rho_b:.3f}, p={p_b:.3g}\")\n",
    "else:\n",
    "    rho_b = np.nan\n",
    "    print(\"BEFORE — Not enough complete pairs.\")\n",
    "\n",
    "# --- 4) AFTER scatter + stats ---\n",
    "n_a, mu_a, sd_a, mask_a = pair_stats(pgd_after, num2)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(pgd_after[mask_a], num2[mask_a], alpha=___)   # e.g., 0.5\n",
    "plt.title(f\"PGD (imputed) vs ___\")                        # fill with num2_var\n",
    "plt.xlabel(\"___\")                                         # e.g., \"PGD sum (imputed)\"\n",
    "plt.ylabel(\"___\")                                         # e.g., num2_var\n",
    "try: savefig(f\"3_8_pgd_imputed_vs___\")                    # fill with num2_var\n",
    "except: pass\n",
    "plt.show()\n",
    "\n",
    "if n_a > 1:\n",
    "    rho_a, p_a = spearmanr(pgd_after[mask_a], num2[mask_a])\n",
    "    print(f\"AFTER  — n={n_a}, mean={mu_a:.2f}, sd={sd_a:.2f}; Spearman rho={rho_a:.3f}, p={p_a:.3g}\")\n",
    "else:\n",
    "    rho_a = np.nan\n",
    "    print(\"AFTER — Not enough complete pairs.\")\n",
    "\n",
    "# --- 5) One-liner deltas (imputed − strict) ---\n",
    "delta_n = (n_a - n_b)\n",
    "delta_rho = (rho_a - rho_b) if np.isfinite(rho_a) and np.isfinite(rho_b) else np.nan\n",
    "print(f\"Δn = {delta_n:+d}; Δrho = {delta_rho:+.3f} (imputed − strict)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "### 🤖 Copilot prompts (use one at a time)\n",
    "\n",
    "- “Using the BEFORE and AFTER summary readouts (n, mean, sd, rho, p), describe whether each measure **increased, decreased, or stayed similar** after imputation—avoid quoting the actual numbers.”\n",
    "- “Explain in 2–3 sentences why **Spearman’s ρ** is appropriate for PGD composites and many ABCD variables (discrete, skewed, with ties).”\n",
    "- “Write one sentence on how **row‑wise mean imputation** can change **n** and potentially **ρ**, even under MCAR.”\n",
    "- “Suggest a **figure caption** for the two scatter plots that helps a non‑technical reader understand what changed from BEFORE to AFTER.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "# Lab 3 — Autograder Checklist & Grade Rubric *(Dataset-Free)* (**50 pts**)\n",
    "\n",
    "This autograder **does not execute your notebook or require any dataset**.  \n",
    "It parses `Lab3.ipynb` and checks for **variable names, assignments, and code patterns**.  \n",
    "Keep the **exact names** and show the required **expressions** in code cells.\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ What you must include (names & patterns must match)\n",
    "\n",
    "**You may choose any valid columns**, but your code must define the items below exactly as named.\n",
    "\n",
    "### 1) Notebook Load & Setup\n",
    "- `df` must be assigned by reading the CSV with `pd.read_csv(...)` into **exactly** `df`.\n",
    "- No unfinished placeholders: all `___` in the provided starter cells must be replaced.\n",
    "\n",
    "### 2) Outlier Handling — Hair Toxicology\n",
    "- A variable (e.g., `cap_choice`) must be set to **one** of the approved strings:  \n",
    "  `\"log_iqr_upper\"`, `\"log_p995\"`, `\"min_of_both\"`, `\"none\"`.\n",
    "- Code must apply the selected approach to the variable chosen for outlier analysis.\n",
    "- A plausibility flag must be created for values above the **literature upper**.\n",
    "\n",
    "### 3) Inconsistencies — Discordant Flag\n",
    "- Uses `SR_VAR` and `HAIR_VAR` from the approved list for past-year self-report and hair screen.\n",
    "- Special codes replaced exactly as shown: `{777: np.nan, 888: np.nan, 999: np.nan}`, plus hair `666 → NaN`.\n",
    "- Discordant flag defined as: `(sr == 0) & (hair == 1)` (with correct `.astype(\"Int64\")`).\n",
    "- Summary table built with the helper function from starter code and includes the discordant flag.\n",
    "\n",
    "### 4) Bivariate — 3.8 “Your Turn” (Mirrors 3.7)\n",
    "- Creates a sum variable from the `pgd_items` list (exact 8 items) with special code replacement `{777: np.nan, 999: np.nan}`.\n",
    "- Selects `num2_var` from the approved numeric list.\n",
    "- Scatter plot created with correct `plt.scatter(...)` call and `savefig` filename:  \n",
    "  `q8_scatter_pgd_vs_{num2_var}`.\n",
    "- Spearman correlation computed with `spearmanr(...)` using a `mask` to drop missing pairs.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Grade Rubric (how points are earned)\n",
    "\n",
    "### 1) Smoke & Structure (**10 pts**)\n",
    "- **5 pts** — All placeholders `___` are replaced; no `TODO` or unfinished code remains.\n",
    "- **5 pts** — `df` is assigned from `pd.read_csv(...)` exactly.\n",
    "\n",
    "### 2) Outlier Handling (**10 pts**)\n",
    "- **4 pts** — `cap_choice` set to one of the four approved strings.\n",
    "- **6 pts** — Code applies the chosen method and defines a plausibility flag above literature upper.\n",
    "\n",
    "### 3) Inconsistencies — Discordant Flag (**10 pts**)\n",
    "- **4 pts** — Correct `SR_VAR`/`HAIR_VAR` used, special code replacement exact.\n",
    "- **6 pts** — Discordant flag formula correct and summary table includes it.\n",
    "\n",
    "### 4) Bivariate — 3.8 Sum Creation (**10 pts**)\n",
    "- **5 pts** — Correct PGD sum from 8 items with special code replacement.\n",
    "- **5 pts** — `num2_var` set from approved list.\n",
    "\n",
    "### 5) Bivariate — 3.8 Plot & Correlation (**10 pts**)\n",
    "- **4 pts** — Scatter plot with correct labels, alpha, and save filename.\n",
    "- **6 pts** — Spearman correlation computed correctly with a missing-data mask.\n",
    "\n",
    "**Total = 50 pts**\n",
    "\n",
    "---\n",
    "\n",
    "## ☑️ Quick Pre-Submission Checklist\n",
    "\n",
    "- [ ] All `___` replaced; no `TODO` markers remain.\n",
    "- [ ] I loaded the dataset with `df = pd.read_csv(...)`.\n",
    "- [ ] I set `cap_choice` to one of: `\"log_iqr_upper\"`, `\"log_p995\"`, `\"min_of_both\"`, `\"none\"`.\n",
    "- [ ] I created a plausibility flag for values above literature upper.\n",
    "- [ ] I used correct variable names for past-year self-report and hair screen, replaced special codes, and built the discordant flag.\n",
    "- [ ] My summary table includes the discordant flag row.\n",
    "- [ ] I built the PGD sum from exactly 8 items with `{777: np.nan, 999: np.nan}` replacement.\n",
    "- [ ] I set `num2_var` from the approved list.\n",
    "- [ ] My scatter plot and save filename match the required format.\n",
    "- [ ] I computed Spearman correlation using a `mask` to drop missing pairs.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔎 Common Pitfalls\n",
    "\n",
    "- Leaving `___` in place.\n",
    "- Using unapproved column names.\n",
    "- Misspelling `cap_choice` or using the wrong string.\n",
    "- Forgetting `.astype(\"Int64\")` for the discordant flag.\n",
    "- Changing the save filename format.\n",
    "- Missing `{777: np.nan, 999: np.nan}` replacement.\n",
    "\n",
    "---\n",
    "\n",
    "## 📤 Submission\n",
    "\n",
    "Upload **only** `Lab3.ipynb` to Gradescope. The autograder reads your notebook and checks for the required names and code patterns — **no dataset needed**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "# Citations\n",
    "\n",
    "### Benchmarking Hair Toxicology Outliers (with citations)\n",
    "\n",
    "Use these published anchors (pg/mg) plus ABCD vendor thresholds (**LOQ = 40**, **LOD = 20**) when deciding whether to **keep**, **cap**, or **transform** a flagged value. For this lab, treat the listed “upper benchmark” as a practical ceiling unless you can justify a unit correction (e.g., ÷1000 for ng→pg).\n",
    "\n",
    "- **Hydrocodone**  \n",
    "  - **Upper benchmark for this lab:** **15,000 pg/mg**  \n",
    "  - Notes: Positive hair concentrations are typically in the low 10²–10³ pg/mg range; higher values occur in heavy/chronic use but are uncommon in community samples.  \n",
    "  - **Citation:** Christine Moore, Michael Feldman, Edward Harrison, Sumandeep Rana, Cynthia Coulter, David Kuntz, Alpana Agrawal, Michael Vincent, James Soares. *Disposition of Hydrocodone in Hair.* **Journal of Analytical Toxicology** 30(6):353–359, 2006.\n",
    "\n",
    "- **Codeine**  \n",
    "  - **Upper benchmark for this lab:** **20,000 pg/mg**  \n",
    "  - Notes: Confirmed positives often fall below a few thousand pg/mg; higher values occur in some users but remain rare.  \n",
    "  - **Citation:** Christine Moore, Michael Feldman, Edward Harrison, Sumandeep Rana, Cynthia Coulter, David Kuntz, Alpana Agrawal, Michael Vincent, James Soares. *Disposition of Hydrocodone in Hair.* **Journal of Analytical Toxicology** 30(6):353–359, 2006. (Includes codeine data in the study.)\n",
    "\n",
    "- **Oxycodone**  \n",
    "  - **Upper benchmark for this lab:** **26,000 pg/mg**  \n",
    "  - Notes: Large series report typical oxycodone positives in the 10³ pg/mg range, with upper observations reaching the mid-10⁴ pg/mg.  \n",
    "  - **Citation:** Reisfield GM, Jones JT. *The Disposition of Oxycodone and Metabolite in Human Hair.* **Journal of Analytical Toxicology** 39(9):746–750, 2015. doi:10.1093/jat/bkv076.\n",
    "\n",
    "- **Morphine**  \n",
    "  - **Upper benchmark for this lab:** **13,000 pg/mg**  \n",
    "  - Notes: Segmental testing in chronic users shows high values up to ~1.3×10⁴ pg/mg; single-use cases are typically much lower.  \n",
    "  - **Citation:** Madry MM, Poetzsch SN, Steuer AE, Kraemer T, Baumgartner MR. *Significance of Metabolite Ratios in the Interpretation of Segmental Hair Testing Results—Differentiation of Single from Chronic Morphine Use in a Case Series.* **Metabolites** 11(8):557, 2021. PMCID: PMC8400298.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
